<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ðŸ”¬ Voice Assistant</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; background: #0f172a; color: white; text-align: center; padding: 20px; }
        .container { max-width: 950px; margin: auto; background: #1e293b; padding: 30px; border-radius: 15px; }
        button { padding: 15px 30px; font-size: 18px; border: none; border-radius: 50px; cursor: pointer; margin-top: 20px; }
        .btn-record { background: #ef4444; color: white; }
        .btn-record.recording { background: #22c55e; animation: pulse 1.5s infinite; }
        #status { margin-top: 20px; font-weight: bold; color: #94a3b8; }
        .lab-grid { display: flex; gap: 20px; margin-top: 30px; }
        .chat-column { flex: 1; background: #0f172a; padding: 15px; border-radius: 10px; border: 2px solid #334155; text-align: left; }
        @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ”¬ Voice Assistant</h1>
        <button id="recordBtn" class="btn-record">Start </button>
        <div id="status">Status: Ready</div>
        <div class="lab-grid">
            <div class="chat-column" style="border-color: #ef4444;">
                <h3 style="color: #ef4444;">ðŸ”´ RAW SIGNAL</h3>
                <button onclick="playComparison('raw')" style="padding: 5px 10px; font-size: 12px; margin-bottom: 10px;">ðŸ”Š Play Raw</button>
                <p><strong>User:</strong> <span id="userTextRaw">-</span></p><hr>
                <p><strong>Res:</strong> <span id="assistantTextRaw">-</span></p>
            </div>
            <div class="chat-column" style="border-color: #22c55e;">
                <h3 style="color: #22c55e;">ðŸŸ¢ CLEAN SIGNAL (VAD)</h3>
                <button onclick="playComparison('clean')" style="padding: 5px 10px; font-size: 12px; margin-bottom: 10px;">ðŸ”Š Play Clean</button>
                <p><strong>User:</strong> <span id="userTextClean">-</span></p><hr>
                <p><strong>Res:</strong> <span id="assistantTextClean">-</span></p>
            </div>
        </div>
        <button id="playBtn" style="display:none; background:#22c55e; width:100%;">ðŸ”Š Replay Response</button>
    </div>

<script>
    const BACKEND_URL = "https://nonpreservative-dora-unexcusedly.ngrok-free.dev/ask_sts";
    const SILENCE_THRESHOLD = 0.035; 
    const SILENCE_DURATION = 1500; 

    let currentRawAudio = null;
    let currentCleanAudio = null;
    let audioContext, analyser, silenceTimer, mediaRecorder;
    let audioChunks = [];
    let isListeningMode = false;
    const audioPlayer = new Audio();

    const recordBtn = document.getElementById('recordBtn');
    const statusText = document.getElementById('status');

   function playComparison(type) {
    const base64 = (type === 'raw') ? currentRawAudio : currentCleanAudio;
    if (base64) {
        // iPhone 11 (Safari) sangat lancar putar audio/mpeg (MP3)
        const tempAudio = new Audio(`data:audio/mpeg;base64,${base64}`); 
        tempAudio.play().catch(e => alert("Gagal putar MP3: " + e));
    } else {
        alert("Audio data belum tersedia!");
    }
}

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            
            // Deteksi format yang didukung browser (PENTING buat iPhone)
            const mimeType = MediaRecorder.isTypeSupported('audio/mp4') ? 'audio/mp4' : 'audio/webm';
            mediaRecorder = new MediaRecorder(stream, { mimeType });
            
            audioChunks = [];
            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            mediaRecorder.onstop = sendAudio;
            mediaRecorder.start();
            
            recordBtn.classList.add('recording');
            recordBtn.innerText = "Listening...";
            statusText.innerText = `Status: Recording (${mimeType})`;
            
            startSilenceDetection(stream);
        } catch (err) {
            statusText.innerText = "Status: Mic Access Denied!";
            isListeningMode = false;
        }
    }

    async function sendAudio() {
        // Gunakan type sesuai format MediaRecorder
        const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
        const formData = new FormData();
        formData.append('audio_raw', audioBlob, 'raw.mp3');
        formData.append('audio_clean', audioBlob, 'clean.mp3');

        try {
            statusText.innerText = "Status: Processing...";
            const response = await fetch(BACKEND_URL, { method: 'POST', body: formData });
            const data = await response.json();
            
            document.getElementById('userTextRaw').innerText = data.raw.text;
            document.getElementById('assistantTextRaw').innerText = data.raw.response;
            document.getElementById('userTextClean').innerText = data.clean.text;
            document.getElementById('assistantTextClean').innerText = data.clean.response;
            
            currentRawAudio = data.raw.audio;
            currentCleanAudio = data.clean.audio;
            
            statusText.innerText = "Status: Analysis Complete";

            if (data.audio) {
                audioPlayer.src = `data:audio/mpeg;base64,${data.audio}`; // gTTS adalah MP3!
                audioPlayer.play().catch(e => console.warn("Autoplay blocked:", e));
            }
            document.getElementById('playBtn').style.display = "block";
        } catch (err) {
            statusText.innerText = "Status: Backend Error!";
            console.error(err);
        }
    }

    function startSilenceDetection(stream) {
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        if (audioContext.state === 'suspended') {
            audioContext.resume();
        }

        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);
        
        const dataArray = new Float32Array(analyser.frequencyBinCount);

        function check() {
            if (!isListeningMode || !mediaRecorder || mediaRecorder.state === "inactive") return;
            analyser.getFloatTimeDomainData(dataArray);
            
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) sum += dataArray[i] * dataArray[i];
            let rms = Math.sqrt(sum / dataArray.length);

            if (rms < SILENCE_THRESHOLD) {
                if (!silenceTimer) silenceTimer = setTimeout(stopRecordingAction, SILENCE_DURATION);
            } else {
                clearTimeout(silenceTimer); silenceTimer = null;
            }
            requestAnimationFrame(check);
        }
        check();
    }

    function stopRecordingAction() {
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
            mediaRecorder.stop();
            // JANGAN tutup context di sini biar loop lancar
        }
    }

    recordBtn.addEventListener('click', () => {
        if (!isListeningMode) {
            isListeningMode = true;
            startRecording();
        } else {
            isListeningMode = false;
            stopRecordingAction();
            recordBtn.innerText = "Start";
            recordBtn.classList.remove('recording');
        }
    });

    audioPlayer.onended = () => {
        if (isListeningMode) setTimeout(startRecording, 500);
    };
</script>
</body>
</html>