<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> Voice Assistant</title>
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #0f172a; color: white; text-align: center; padding: 20px; }
        .container { max-width: 600px; margin: auto; background: #1e293b; padding: 30px; border-radius: 15px; box-shadow: 0 4px 20px rgba(0,0,0,0.5); }
        button { padding: 15px 30px; font-size: 18px; border: none; border-radius: 50px; cursor: pointer; transition: 0.3s; margin-top: 20px; }
        .btn-record { background: #ef4444; color: white; }
        .btn-record.recording { background: #22c55e; animation: pulse 1.5s infinite; }
        #status { margin-top: 20px; font-weight: bold; color: #94a3b8; }
        #chat-box { margin-top: 30px; text-align: left; background: #0f172a; padding: 15px; border-radius: 10px; min-height: 100px; border: 1px solid #334155; }
        @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
    </style>
</head>
<body>
<div class="container" style="max-width: 900px;"> <h1>ðŸ”¬ STS Comparative Lab</h1>
    <p>Dikembangkan oleh: <strong>Gania Rafidah</strong> | NIM: 235150301111047</p>
    
    <button id="recordBtn" class="btn-record">Start Research Mode</button>
    <div id="status">Status: Ready</div>

    <div style="display: flex; gap: 20px; margin-top: 30px;">
        <div id="chat-box" style="flex: 1; border-color: #ef4444;">
            <h3 style="color: #ef4444;">ðŸ”´ RAW Signal (With Noise)</h3>
            <p><strong>ASR Text:</strong> <span id="userTextRaw">-</span></p>
            <hr style="border-color: #334155;">
            <p><strong>Response:</strong> <span id="assistantTextRaw">-</span></p>
        </div>

        <div id="chat-box" style="flex: 1; border-color: #22c55e;">
            <h3 style="color: #22c55e;">ðŸŸ¢ CLEAN Signal (VAD Active)</h3>
            <p><strong>ASR Text:</strong> <span id="userTextClean">-</span></p>
            <hr style="border-color: #334155;">
            <p><strong>Response:</strong> <span id="assistantTextClean">-</span></p>
        </div>
    </div>
    
    <button id="playBtn" style="display:none; background:#22c55e; width:100%;">ðŸ”Š Putar Jawaban (Clean Only)</button>
</div>

<script>
    const userOutputRaw = document.getElementById('userTextRaw');
    const assistantOutputRaw = document.getElementById('assistantTextRaw');
    const userOutputClean = document.getElementById('userTextClean');
    const assistantOutputClean = document.getElementById('assistantTextClean');

    async function sendAudio() {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        const formData = new FormData();
        
        formData.append('audio_raw', audioBlob, 'raw.wav');
        formData.append('audio_clean', audioBlob, 'clean.wav');

        try {
            const response = await fetch(BACKEND_URL, { method: 'POST', body: formData });
            const data = await response.json();
            
            userOutputRaw.innerText = data.raw.text;
            assistantOutputRaw.innerText = data.raw.response;

            userOutputClean.innerText = data.clean.text;
            assistantOutputClean.innerText = data.clean.response;
            
            statusText.innerText = "Status: Comparison Complete";

            if (data.audio) {
                audioPlayer.src = `data:audio/wav;base64,${data.audio}`;
                audioPlayer.play();
            }
            
            if (isListeningMode) setTimeout(startRecording, 1000);
        } catch (err) {
            statusText.innerText = "Status: Connection Error!";
            if (isListeningMode) setTimeout(startRecording, 2000);
        }
    }
    audioPlayer.onended = () => {
        if (isListeningMode) {
            console.log("Loop: Assistant finished speaking. Returning to listening mode...");
            setTimeout(startRecording, 300);
        }
    };

    function startSilenceDetection(stream) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 512;
        source.connect(analyser);

        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Float32Array(bufferLength);

        function checkVolume() {
            if (!recordBtn.classList.contains('recording')) return;

            analyser.getFloatTimeDomainData(dataArray);
            let sum = 0;
            for (let i = 0; i < bufferLength; i++) {
                sum += dataArray[i] * dataArray[i];
            }
            let rmsValue = Math.sqrt(sum / bufferLength); 

            if (rmsValue < SILENCE_THRESHOLD) {
                if (!silenceTimer) {
                    silenceTimer = setTimeout(() => {
                        stopRecordingAction();
                    }, SILENCE_DURATION);
                }
            } else {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }
            requestAnimationFrame(checkVolume);
        }
        checkVolume();
    }

    playBtn.addEventListener('click', () => {
        audioPlayer.play();
        playBtn.style.display = "none";
    });
</script>
</body>
</html>